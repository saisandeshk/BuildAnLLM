"""Trainer for Supervised Fine-Tuning (SFT)."""

import torch
import torch.nn as nn
import torch.nn.functional as F
import os
from tqdm import tqdm
from finetuning.training.finetuning_args import FinetuningArgs


class SFTTrainer:
    """
    Trainer for supervised fine-tuning (SFT).

    **Key Differences from Pre-Training:**

    1. **Masked Loss**: Only computes loss on response tokens (where mask == 1),
       ignoring prompt tokens. This teaches the model to generate responses,
       not repeat prompts.

    2. **Lower Learning Rate**: Typically 10-100x lower than pre-training
       (e.g., 1e-5 vs 1e-3) to make small adjustments to pre-trained weights.

    3. **Shorter Training**: Usually 1-5 epochs vs 10+ for pre-training,
       since we're fine-tuning, not training from scratch.

    4. **Structured Data**: Trains on prompt/response pairs instead of raw text,
       teaching instruction-following behavior.

    **Training Process:**
    1. Load pre-trained model (architecture + weights)
    2. Continue training on prompt/response pairs
    3. Compute masked loss (only on response tokens)
    4. Update weights with lower learning rate
    5. Save fine-tuned checkpoints

    **Note**: This trainer reuses the same transformer architecture from pre-training.
    The model itself may use einops or not (determined by the pre-trained checkpoint).
    """

    def __init__(
        self,
        model: nn.Module,
        args: FinetuningArgs,
        X_train: torch.Tensor,
        Y_train: torch.Tensor,
        masks_train: torch.Tensor,
        X_val: torch.Tensor,
        Y_val: torch.Tensor,
        masks_val: torch.Tensor,
        device: torch.device,
        eval_interval: int = 500,
        print_interval: int = 100,
        tokenizer_type: str = None,
    ):
        self.model = model
        self.args = args
        self.X_train = X_train
        self.Y_train = Y_train
        self.masks_train = masks_train
        self.X_val = X_val
        self.Y_val = Y_val
        self.masks_val = masks_val
        self.device = device
        self.eval_interval = eval_interval
        self.eval_iters = args.eval_iters
        self.print_interval = print_interval
        self.tokenizer_type = tokenizer_type

        # Setup optimizer (lower learning rate than pre-training)
        # If using LoRA, only optimize LoRA parameters
        if hasattr(args, 'use_lora') and args.use_lora:
            from finetuning.peft.lora_utils import get_lora_parameters
            trainable_params = get_lora_parameters(self.model)
            if len(trainable_params) == 0:
                raise ValueError(
                    "No LoRA parameters found! Make sure LoRA was applied correctly to the model. "
                    "Check that convert_model_to_lora was called before creating the trainer."
                )
            print(f"Optimizing {len(trainable_params)} LoRA parameter groups")
        else:
            trainable_params = [
                p for p in self.model.parameters() if p.requires_grad]
            if len(trainable_params) == 0:
                raise ValueError(
                    "No trainable parameters found! All model parameters are frozen. "
                    "This might happen if LoRA was applied but use_lora=False, or if all parameters were manually frozen."
                )

        self.optimizer = torch.optim.AdamW(
            trainable_params, lr=args.lr, weight_decay=args.weight_decay
        )

        # Calculate max_iters
        self.max_iters = args.epochs * args.max_steps_per_epoch

        # Track running average of loss
        self.running_loss = None
        self.loss_alpha = 0.99

        # Track losses for plotting
        self.train_losses = []
        self.val_losses = []
        self.iterations = []

        # Create save directory if it doesn't exist
        if args.save_dir:
            os.makedirs(args.save_dir, exist_ok=True)

    def _compute_masked_loss(
        self,
        logits: torch.Tensor,
        targets: torch.Tensor,
        masks: torch.Tensor
    ) -> torch.Tensor:
        """Compute masked cross-entropy loss.

        Only computes loss on response tokens (where mask == 1), ignoring prompt tokens.
        This is the key difference from pre-training: we teach the model to generate
        responses, not repeat prompts.

        Formula:
            loss = sum(loss_per_token * mask) / sum(mask)

        Args:
            logits: Model predictions [batch_size, seq_len, vocab_size]
            targets: Target token IDs [batch_size, seq_len]
            masks: Loss masks [batch_size, seq_len] (1 for response, 0 for prompt)

        Returns:
            Scalar masked loss (average over response tokens only)
        """
        # Reshape for cross_entropy
        # [batch_size * seq_len, vocab_size]
        logits_flat = logits.view(-1, logits.size(-1))
        targets_flat = targets.view(-1)  # [batch_size * seq_len]
        masks_flat = masks.view(-1)  # [batch_size * seq_len]

        # Cross-entropy loss per token (before masking)
        loss_unmasked = F.cross_entropy(
            logits_flat, targets_flat, reduction='none')

        # Apply mask: multiply by mask (0 for prompt, 1 for response), then average
        # Only response tokens contribute to loss
        loss = (loss_unmasked * masks_flat).sum() / \
            masks_flat.sum().clamp(min=1)

        return loss

    def _evaluate_batch(
        self,
        x_batch: torch.Tensor,
        y_batch: torch.Tensor,
        masks_batch: torch.Tensor
    ) -> float:
        """Compute masked loss for a single batch.

        Args:
            x_batch: Input tokens [batch_size, seq_len]
            y_batch: Target tokens [batch_size, seq_len]
            masks_batch: Loss masks [batch_size, seq_len] (1 for response, 0 for prompt)

        Returns:
            Loss value (scalar float)
        """
        result = self.model(x_batch)
        # Handle tuple return (logits, cache) - extract just logits
        logits = result[0] if isinstance(result, tuple) else result
        loss = self._compute_masked_loss(logits, y_batch, masks_batch)
        return loss.item()

    def _evaluate_split(
        self,
        split_name: str,
        split_X: torch.Tensor,
        split_Y: torch.Tensor,
        split_masks: torch.Tensor
    ) -> float:
        """Evaluate one split (train or val) with masked loss.

        Computes average masked loss over multiple random batches from the split.
        Only computes loss on response tokens (where mask == 1).

        Args:
            split_name: Name of split ("train" or "val")
            split_X: Input tokens for split
            split_Y: Target tokens for split
            split_masks: Loss masks for split

        Returns:
            Average masked loss over evaluation iterations
        """
        losses = torch.zeros(self.eval_iters)
        for k in tqdm(
            range(self.eval_iters),
            desc=f"Evaluating {split_name}",
            leave=False,
        ):
            # Random batch
            idx = torch.randint(0, len(split_X), (self.args.batch_size,))
            x_batch = split_X[idx].to(self.device)
            y_batch = split_Y[idx].to(self.device)
            masks_batch = split_masks[idx].to(self.device)

            losses[k] = self._evaluate_batch(x_batch, y_batch, masks_batch)

        return losses.mean().item()

    @torch.no_grad()
    def estimate_loss(self):
        """Estimate loss on train and val sets."""
        out = {}
        self.model.eval()

        # Evaluate train split
        out["train"] = self._evaluate_split(
            "train", self.X_train, self.Y_train, self.masks_train
        )

        # Evaluate val split
        out["val"] = self._evaluate_split(
            "val", self.X_val, self.Y_val, self.masks_val
        )

        self.model.train()
        return out

    def train(self):
        """Main training loop."""
        print("\nStarting fine-tuning...")
        print(
            f"Training for {self.args.epochs} epochs, {self.max_iters} total iterations")
        print(
            f"Batch size: {self.args.batch_size}, Learning rate: {self.args.lr}")
        print(f"Weight decay: {self.args.weight_decay}")
        print(f"Evaluating every {self.eval_interval} iterations\n")

        pbar = tqdm(range(self.max_iters), desc="Fine-tuning")
        for iter_num in pbar:
            # Get random batch
            # idx: [batch_size] - random indices into training set
            idx = torch.randint(0, len(self.X_train), (self.args.batch_size,))
            # x_batch: [batch_size, seq_len] - input token sequences
            # y_batch: [batch_size, seq_len] - target token sequences (shifted by 1)
            # masks_batch: [batch_size, seq_len] - loss masks (1 for response, 0 for prompt)
            x_batch = self.X_train[idx].to(self.device)
            y_batch = self.Y_train[idx].to(self.device)
            masks_batch = self.masks_train[idx].to(self.device)

            # Forward pass
            # logits: [batch_size, seq_len, vocab_size] - model predictions
            result = self.model(x_batch)
            # Handle tuple return (logits, cache) - extract just logits
            logits = result[0] if isinstance(result, tuple) else result

            # Compute masked loss (only on response tokens)
            # Key difference from pre-training: we ignore loss on prompt tokens
            # This teaches the model to generate responses, not repeat prompts
            loss = self._compute_masked_loss(logits, y_batch, masks_batch)

            # Backward pass
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()

            # Update running loss
            if self.running_loss is None:
                self.running_loss = loss.item()
            else:
                self.running_loss = (
                    self.loss_alpha * self.running_loss
                    + (1 - self.loss_alpha) * loss.item()
                )

            # Update progress bar
            pbar.set_postfix({
                "loss": f"{loss.item():.4f}",
                "avg_loss": f"{self.running_loss:.4f}",
            })

            # Print detailed loss periodically
            if iter_num % self.print_interval == 0 and iter_num > 0:
                print(
                    f"\n[Iter {iter_num}] Current loss: {loss.item():.4f}, "
                    f"Running avg: {self.running_loss:.4f}"
                )

            # Evaluate at intervals
            should_eval = (
                (iter_num > 0 and iter_num % self.eval_interval == 0)
                or iter_num == self.max_iters - 1
            )
            if should_eval:
                losses = self.estimate_loss()
                print(
                    f"\n[Iter {iter_num}] Train loss: {losses['train']:.4f}, "
                    f"Val loss: {losses['val']:.4f}"
                )
                self.iterations.append(iter_num)
                self.train_losses.append(losses['train'])
                self.val_losses.append(losses['val'])
                pbar.set_postfix({
                    "loss": f"{loss.item():.4f}",
                    "avg_loss": f"{self.running_loss:.4f}",
                    "val_loss": f"{losses['val']:.4f}",
                })

            # Save checkpoint
            if (
                hasattr(self.args, "save_interval")
                and iter_num % self.args.save_interval == 0
                and iter_num > 0
            ):
                self.save_checkpoint(iter_num)

        pbar.close()
        print("\nFine-tuning complete!")
        print(f"Final running average loss: {self.running_loss:.4f}")

        # Save final checkpoint
        if self.args.save_dir:
            self.save_checkpoint(self.max_iters, is_final=True)

    def save_checkpoint(self, iter_num: int, is_final: bool = False):
        """Save model checkpoint."""
        if not self.args.save_dir:
            return

        if is_final:
            filepath = os.path.join(self.args.save_dir, "final_model.pt")
        else:
            filepath = os.path.join(
                self.args.save_dir, f"checkpoint_{iter_num}.pt"
            )

        # Save model config
        cfg = self.model.cfg if hasattr(self.model, "cfg") else None
        cfg_dict = cfg.to_dict() if cfg is not None else None

        # Determine model type
        model_type = "with_einops" if "WithEinops" in self.model.__class__.__name__ else "without_einops"

        # Get state dict
        model_state_dict = self.model.state_dict()

        # If using LoRA, also save LoRA-specific info
        lora_info = None
        if hasattr(self.args, 'use_lora') and self.args.use_lora:
            from finetuning.peft.lora_utils import get_lora_parameters, count_lora_parameters
            param_counts = count_lora_parameters(self.model)
            lora_info = {
                "lora_rank": self.args.lora_rank,
                "lora_alpha": self.args.lora_alpha,
                "lora_dropout": self.args.lora_dropout,
                "lora_target_modules": self.args.lora_target_modules,
                "lora_param_count": param_counts['lora'],
            }

        checkpoint_data = {
            "model_state_dict": model_state_dict,
            "optimizer_state_dict": self.optimizer.state_dict(),
            "iter_num": iter_num,
            "running_loss": self.running_loss,
            "args": self.args,
            "cfg": cfg_dict,
            "model_type": model_type,
            "tokenizer_type": self.tokenizer_type,
            "is_finetuned": True,  # Mark as fine-tuned
        }

        # Add LoRA info if present
        if lora_info:
            checkpoint_data["lora_info"] = lora_info
            checkpoint_data["use_lora"] = True

        torch.save(checkpoint_data, filepath)
        if not is_final:
            print(f"Checkpoint saved: {filepath}")

    def train_single_step(self):
        """Perform a single training step (one batch) and return metrics.

        Designed for interactive 'Stepping' in UI.

        Returns:
            dict with metrics: 'loss', 'running_loss', 'grad_norm', 'inputs', 'targets', 'masks'
        """
        # Get random batch
        idx = torch.randint(0, len(self.X_train), (self.args.batch_size,))
        x_batch = self.X_train[idx].to(self.device)
        y_batch = self.Y_train[idx].to(self.device)
        masks_batch = self.masks_train[idx].to(self.device)

        # Forward pass
        result = self.model(x_batch)
        logits = result[0] if isinstance(result, tuple) else result

        # Compute masked loss
        loss = self._compute_masked_loss(logits, y_batch, masks_batch)

        # Backward pass
        self.optimizer.zero_grad()
        loss.backward()

        # Calculate gradient norm
        total_norm = 0.0
        # Only check parameters that require grad (handles LoRA correctly)
        for p in self.model.parameters():
            if p.requires_grad and p.grad is not None:
                param_norm = p.grad.data.norm(2)
                total_norm += param_norm.item() ** 2
        total_norm = total_norm ** 0.5

        self.optimizer.step()

        # Update running loss
        if self.running_loss is None:
            self.running_loss = loss.item()
        else:
            self.running_loss = (
                self.loss_alpha * self.running_loss
                + (1 - self.loss_alpha) * loss.item()
            )

        return {
            "loss": loss.item(),
            "running_loss": self.running_loss,
            "grad_norm": total_norm,
            "inputs": x_batch.detach().cpu(),
            "targets": y_batch.detach().cpu(),
            "masks": masks_batch.detach().cpu()
        }
